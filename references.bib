
@article{strobl_conditional_2008,
	title = {Conditional variable importance for random forests},
	volume = {9},
	issn = {1471-2105},
	url = {https://doi.org/10.1186/1471-2105-9-307},
	doi = {10.1186/1471-2105-9-307},
	abstract = {Random forests are becoming increasingly popular in many scientific fields because they can cope with "small n large p" problems, complex interactions and even highly correlated predictor variables. Their variable importance measures have recently been suggested as screening tools for, e.g., gene expression studies. However, these variable importance measures show a bias towards correlated predictor variables.},
	number = {1},
	urldate = {2023-04-28},
	journal = {BMC Bioinformatics},
	author = {Strobl, Carolin and Boulesteix, Anne-Laure and Kneib, Thomas and Augustin, Thomas and Zeileis, Achim},
	month = jul,
	year = {2008},
	keywords = {Amino Acid Property, Importance Measure, Importance Score, Permutation Scheme, Random Forest},
	pages = {307},
	file = {Full Text PDF:/Users/damar.pramuditya/Zotero/storage/HXG642U5/Strobl et al. - 2008 - Conditional variable importance for random forests.pdf:application/pdf;Snapshot:/Users/damar.pramuditya/Zotero/storage/6TTHC3LT/1471-2105-9-307.html:text/html},
}

@misc{li_debiased_2019,
	title = {A {Debiased} {MDI} {Feature} {Importance} {Measure} for {Random} {Forests}},
	url = {http://arxiv.org/abs/1906.10845},
	doi = {10.48550/arXiv.1906.10845},
	abstract = {Tree ensembles such as Random Forests have achieved impressive empirical success across a wide variety of applications. To understand how these models make predictions, people routinely turn to feature importance measures calculated from tree ensembles. It has long been known that Mean Decrease Impurity (MDI), one of the most widely used measures of feature importance, incorrectly assigns high importance to noisy features, leading to systematic bias in feature selection. In this paper, we address the feature selection bias of MDI from both theoretical and methodological perspectives. Based on the original definition of MDI by Breiman et al. for a single tree, we derive a tight non-asymptotic bound on the expected bias of MDI importance of noisy features, showing that deep trees have higher (expected) feature selection bias than shallow ones. However, it is not clear how to reduce the bias of MDI using its existing analytical expression. We derive a new analytical expression for MDI, and based on this new expression, we are able to propose a debiased MDI feature importance measure using out-of-bag samples, called MDI-oob. For both the simulated data and a genomic ChIP dataset, MDI-oob achieves state-of-the-art performance in feature selection from Random Forests for both deep and shallow trees.},
	urldate = {2023-04-28},
	publisher = {arXiv},
	author = {Li, Xiao and Wang, Yu and Basu, Sumanta and Kumbier, Karl and Yu, Bin},
	month = oct,
	year = {2019},
	note = {arXiv:1906.10845 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {arXiv Fulltext PDF:/Users/damar.pramuditya/Zotero/storage/Q39SHPUC/Li et al. - 2019 - A Debiased MDI Feature Importance Measure for Rand.pdf:application/pdf;arXiv.org Snapshot:/Users/damar.pramuditya/Zotero/storage/QJJIRZD2/1906.html:text/html},
}

@article{janitza_overestimation_2018,
	title = {On the overestimation of random forest’s out-of-bag error},
	volume = {13},
	issn = {1932-6203},
	url = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0201904},
	doi = {10.1371/journal.pone.0201904},
	abstract = {The ensemble method random forests has become a popular classification tool in bioinformatics and related fields. The out-of-bag error is an error estimation technique often used to evaluate the accuracy of a random forest and to select appropriate values for tuning parameters, such as the number of candidate predictors that are randomly drawn for a split, referred to as mtry. However, for binary classification problems with metric predictors it has been shown that the out-of-bag error can overestimate the true prediction error depending on the choices of random forests parameters. Based on simulated and real data this paper aims to identify settings for which this overestimation is likely. It is, moreover, questionable whether the out-of-bag error can be used in classification tasks for selecting tuning parameters like mtry, because the overestimation is seen to depend on the parameter mtry. The simulation-based and real-data based studies with metric predictor variables performed in this paper show that the overestimation is largest in balanced settings and in settings with few observations, a large number of predictor variables, small correlations between predictors and weak effects. There was hardly any impact of the overestimation on tuning parameter selection. However, although the prediction performance of random forests was not substantially affected when using the out-of-bag error for tuning parameter selection in the present studies, one cannot be sure that this applies to all future data. For settings with metric predictor variables it is therefore strongly recommended to use stratified subsampling with sampling fractions that are proportional to the class sizes for both tuning parameter selection and error estimation in random forests. This yielded less biased estimates of the true prediction error. In unbalanced settings, in which there is a strong interest in predicting observations from the smaller classes well, sampling the same number of observations from each class is a promising alternative.},
	language = {en},
	number = {8},
	urldate = {2023-04-28},
	journal = {PLOS ONE},
	author = {Janitza, Silke and Hornung, Roman},
	month = aug,
	year = {2018},
	note = {Publisher: Public Library of Science},
	keywords = {Breast cancer, Colorectal cancer, Forecasting, Genomics, Normal distribution, Prostate cancer, Simulation and modeling, Trees},
	pages = {e0201904},
	file = {Full Text PDF:/Users/damar.pramuditya/Zotero/storage/7WHV9NIK/Janitza and Hornung - 2018 - On the overestimation of random forest’s out-of-ba.pdf:application/pdf},
}

@article{probst_hyperparameters_2019,
	title = {Hyperparameters and {Tuning} {Strategies} for {Random} {Forest}},
	volume = {9},
	issn = {1942-4787, 1942-4795},
	url = {http://arxiv.org/abs/1804.03515},
	doi = {10.1002/widm.1301},
	abstract = {The random forest algorithm (RF) has several hyperparameters that have to be set by the user, e.g., the number of observations drawn randomly for each tree and whether they are drawn with or without replacement, the number of variables drawn randomly for each split, the splitting rule, the minimum number of samples that a node must contain and the number of trees. In this paper, we first provide a literature review on the parameters' influence on the prediction performance and on variable importance measures. It is well known that in most cases RF works reasonably well with the default values of the hyperparameters specified in software packages. Nevertheless, tuning the hyperparameters can improve the performance of RF. In the second part of this paper, after a brief overview of tuning strategies we demonstrate the application of one of the most established tuning strategies, model-based optimization (MBO). To make it easier to use, we provide the tuneRanger R package that tunes RF with MBO automatically. In a benchmark study on several datasets, we compare the prediction performance and runtime of tuneRanger with other tuning implementations in R and RF with default hyperparameters.},
	number = {3},
	urldate = {2023-04-28},
	journal = {WIREs Data Mining Knowl Discov},
	author = {Probst, Philipp and Wright, Marvin and Boulesteix, Anne-Laure},
	month = may,
	year = {2019},
	note = {arXiv:1804.03515 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {arXiv Fulltext PDF:/Users/damar.pramuditya/Zotero/storage/3X9KZPWD/Probst et al. - 2019 - Hyperparameters and Tuning Strategies for Random F.pdf:application/pdf;arXiv.org Snapshot:/Users/damar.pramuditya/Zotero/storage/EWBRM3TE/1804.html:text/html},
}

@book{james_introduction_2021,
	address = {New York, NY},
	series = {Springer {Texts} in {Statistics}},
	title = {An {Introduction} to {Statistical} {Learning}: with {Applications} in {R}},
	isbn = {978-1-07-161417-4 978-1-07-161418-1},
	shorttitle = {An {Introduction} to {Statistical} {Learning}},
	url = {https://link.springer.com/10.1007/978-1-0716-1418-1},
	language = {en},
	urldate = {2023-04-28},
	publisher = {Springer US},
	author = {James, Gareth and Witten, Daniela and Hastie, Trevor and Tibshirani, Robert},
	year = {2021},
	doi = {10.1007/978-1-0716-1418-1},
	keywords = {data mining, inference, R, R software, statistical learning, supervised learning, unsupervised learning},
	file = {Submitted Version:/Users/damar.pramuditya/Zotero/storage/N5S5YK2F/James et al. - 2021 - An Introduction to Statistical Learning with Appl.pdf:application/pdf},
}

@misc{noauthor_introduction_nodate,
	title = {An {Introduction} to {Statistical} {Learning}},
	url = {https://www.statlearning.com},
	language = {en-US},
	urldate = {2023-04-28},
	journal = {An Introduction to Statistical Learning},
	file = {Snapshot:/Users/damar.pramuditya/Zotero/storage/CCA35CSJ/www.statlearning.com.html:text/html},
}

@misc{genuer_random_2008,
	title = {Random {Forests}: some methodological insights},
	shorttitle = {Random {Forests}},
	url = {http://arxiv.org/abs/0811.3619},
	doi = {10.48550/arXiv.0811.3619},
	abstract = {This paper examines from an experimental perspective random forests, the increasingly used statistical method for classification and regression problems introduced by Leo Breiman in 2001. It first aims at confirming, known but sparse, advice for using random forests and at proposing some complementary remarks for both standard problems as well as high dimensional ones for which the number of variables hugely exceeds the sample size. But the main contribution of this paper is twofold: to provide some insights about the behavior of the variable importance index based on random forests and in addition, to propose to investigate two classical issues of variable selection. The first one is to find important variables for interpretation and the second one is more restrictive and try to design a good prediction model. The strategy involves a ranking of explanatory variables using the random forests score of importance and a stepwise ascending variable introduction strategy.},
	urldate = {2023-04-28},
	publisher = {arXiv},
	author = {Genuer, Robin and Poggi, Jean-Michel and Tuleau, Christine},
	month = nov,
	year = {2008},
	note = {arXiv:0811.3619 [stat]},
	keywords = {Statistics - Machine Learning},
	file = {arXiv Fulltext PDF:/Users/damar.pramuditya/Zotero/storage/6HYM4SVQ/Genuer et al. - 2008 - Random Forests some methodological insights.pdf:application/pdf;arXiv.org Snapshot:/Users/damar.pramuditya/Zotero/storage/2Q8HB73I/0811.html:text/html},
}

@book{zhang_recursive_2010,
	address = {New York, NY},
	series = {Springer {Series} in {Statistics}},
	title = {Recursive {Partitioning} and {Applications}},
	volume = {0},
	isbn = {978-1-4419-6823-4 978-1-4419-6824-1},
	url = {https://link.springer.com/10.1007/978-1-4419-6824-1},
	language = {en},
	urldate = {2023-04-28},
	publisher = {Springer},
	author = {Zhang, Heping and Singer, Burton H.},
	year = {2010},
	doi = {10.1007/978-1-4419-6824-1},
	keywords = {classification, adIOMEDICIaptive Splines and Regression Trees, calculus, epidemiology, Logistic Regression, Practical Computational Methods, Recursive Partitioning, Tree-based Survival Analysis, Trees and Associated Forests},
	file = {Submitted Version:/Users/damar.pramuditya/Zotero/storage/RNAZ69SH/Zhang and Singer - 2010 - Recursive Partitioning and Applications.pdf:application/pdf},
}

@misc{others_risk-based_nodate,
	title = {Risk-{Based} {Authentication}},
	url = {https://riskbasedauthentication.org/},
	abstract = {Improves password security without degrading usability. Find out which websites use it and all about its security and privacy.},
	language = {en},
	urldate = {2023-04-28},
	journal = {Risk-Based Authentication},
	author = {others, Luigi Lo Iacono, and, Stephan Wiefling},
	file = {Snapshot:/Users/damar.pramuditya/Zotero/storage/PP25NFMS/riskbasedauthentication.org.html:text/html},
}

@misc{noauthor_risk-based_nodate,
	title = {Risk-{Based} {Authentication} {\textbar} {Improves} password security without degrading usability},
	url = {https://riskbasedauthentication.org/},
	urldate = {2023-04-27},
	file = {Risk-Based Authentication | Improves password security without degrading usability:/Users/damar.pramuditya/Zotero/storage/65B8Y6SX/riskbasedauthentication.org.html:text/html},
}

@misc{noauthor_using_nodate,
	title = {Using {Machine} to {Machine} ({M2M}) {Authorization}},
	url = {https://auth0.com/blog/using-m2m-authorization/},
	abstract = {How to set up non-interactive apps using the client credentials grant and Auth0 to perform IoT device, CLI tool, and more machine to mach...},
	language = {en},
	urldate = {2023-04-27},
	journal = {Auth0 - Blog},
	file = {Snapshot:/Users/damar.pramuditya/Zotero/storage/2XY2KBXL/using-m2m-authorization.html:text/html},
}

@incollection{zani_variable_2006,
	address = {Berlin, Heidelberg},
	title = {Variable {Selection} {Using} {Random} {Forests}},
	isbn = {978-3-540-35977-7},
	url = {http://link.springer.com/10.1007/3-540-35978-8_30},
	language = {en},
	urldate = {2023-04-27},
	booktitle = {Data {Analysis}, {Classification} and the {Forward} {Search}},
	publisher = {Springer Berlin Heidelberg},
	author = {Sandri, Marco and Zuccolotto, Paola},
	editor = {Zani, Sergio and Cerioli, Andrea and Riani, Marco and Vichi, Maurizio},
	year = {2006},
	doi = {10.1007/3-540-35978-8_30},
	note = {Series Title: Studies in Classification, Data Analysis, and Knowledge Organization},
	pages = {263--270},
	file = {Submitted Version:/Users/damar.pramuditya/Zotero/storage/HFLL57SK/Sandri and Zuccolotto - 2006 - Variable Selection Using Random Forests.pdf:application/pdf},
}

@article{liaw_classication_2002,
	title = {Classiﬁcation and {Regression} by {randomForest}},
	volume = {2},
	language = {en},
	author = {Liaw, Andy and Wiener, Matthew},
	year = {2002},
	file = {Liaw and Wiener - 2002 - Classiﬁcation and Regression by randomForest.pdf:/Users/damar.pramuditya/Zotero/storage/IE9CFQ6L/Liaw and Wiener - 2002 - Classiﬁcation and Regression by randomForest.pdf:application/pdf},
}

@inproceedings{breiman_random_2003,
	address = {New York, NY},
	title = {Random {Forests}: {Finding} {Quasars}},
	isbn = {978-0-387-21529-7},
	shorttitle = {Random {Forests}},
	doi = {10.1007/0-387-21529-8_16},
	abstract = {The automatic classification of objects from catalogues or other sources of data is a common statistical problem in many astronomical surveys. We describe an effective method, Random Forests, in which votes for class membership are polled from a large random ensemble of tree classifiers. This procedure is illustrated by the problem of identifying quasars from the FIRST survey.},
	language = {en},
	booktitle = {Statistical {Challenges} in {Astronomy}},
	publisher = {Springer},
	author = {Breiman, Leo and Last, Michael and Rice, John},
	editor = {Feigelson, Eric D. and Babu, G. Jogesh},
	year = {2003},
	keywords = {Random Forest, Blue Plate, Bright Quasar, Variable Principal Component Analysis, Virtual Observatory},
	pages = {243--254},
}

@article{breiman_random_2001,
	title = {Random {Forests}},
	volume = {45},
	issn = {1573-0565},
	url = {https://doi.org/10.1023/A:1010933404324},
	doi = {10.1023/A:1010933404324},
	abstract = {Random forests are a combination of tree predictors such that each tree depends on the values of a random vector sampled independently and with the same distribution for all trees in the forest. The generalization error for forests converges a.s. to a limit as the number of trees in the forest becomes large. The generalization error of a forest of tree classifiers depends on the strength of the individual trees in the forest and the correlation between them. Using a random selection of features to split each node yields error rates that compare favorably to Adaboost (Y. Freund \& R. Schapire, Machine Learning: Proceedings of the Thirteenth International conference, ***, 148–156), but are more robust with respect to noise. Internal estimates monitor error, strength, and correlation and these are used to show the response to increasing the number of features used in the splitting. Internal estimates are also used to measure variable importance. These ideas are also applicable to regression.},
	language = {en},
	number = {1},
	urldate = {2023-04-27},
	journal = {Machine Learning},
	author = {Breiman, Leo},
	month = oct,
	year = {2001},
	keywords = {classification, ensemble, regression},
	pages = {5--32},
	file = {Full Text PDF:/Users/damar.pramuditya/Zotero/storage/PZ85EPFB/Breiman - 2001 - Random Forests.pdf:application/pdf},
}

@article{sartono_metode_nodate,
	title = {{METODE} {POHON} {GABUNGAN}: {SOLUSI} {PILIHAN} {UNTUK} {MENGATASI} {KELEMAHAN} {POHON} {REGRESI} {DAN} {KLASIFIKASI} {TUNGGAL}},
	abstract = {Classification and regression tree has been a widely used tool in various applied fields due to its capability to give excellent predictive analysis. Later on, ensemble tree appeared to enhance simple tree analysis and deals with some of the weakness found in simple techniques. The ensemble tree basically combines predictions values of many simple trees into a single prediction value. This paper is intended as an introductory article to give a brief overview of the available ensemble tree methods which might be found in detail in a variety of reading materials.},
	language = {id},
	author = {Sartono, Bagus and Syafitri, Utami Dyah},
	file = {Sartono and Syafitri - METODE POHON GABUNGAN SOLUSI PILIHAN UNTUK MENGAT.pdf:/Users/damar.pramuditya/Zotero/storage/233UWJNY/Sartono and Syafitri - METODE POHON GABUNGAN SOLUSI PILIHAN UNTUK MENGAT.pdf:application/pdf},
}

@inproceedings{gordon_classification_1984,
	title = {Classification and {Regression} {Trees}.},
	volume = {40},
	url = {https://www.jstor.org/stable/2530946?origin=crossref},
	doi = {10.2307/2530946},
	abstract = {Background. Introduction to Tree Classification. Right Sized Trees and Honest Estimates. Splitting Rules. Strengthening and Interpreting. Medical Diagnosis and Prognosis. Mass Spectra Classification. Regression Trees. Bayes Rules and Partitions. Optimal Pruning. Construction of Trees from a Learning Sample. Consistency. Bibliography. Notation Index. Subject Index.},
	urldate = {2023-04-27},
	booktitle = {Biometrics},
	author = {Gordon, A. D. and Breiman, L. and Friedman, J. H. and Olshen, R. A. and Stone, C. J.},
	month = sep,
	year = {1984},
	note = {ISSN: 0006341X
Issue: 3
Journal Abbreviation: Biometrics},
	pages = {874},
}

@article{kim_m2m_2014,
	title = {{M2M} {Service} {Platforms}: {Survey}, {Issues}, and {Enabling} {Technologies}},
	volume = {16},
	issn = {1553-877X},
	shorttitle = {{M2M} {Service} {Platforms}},
	doi = {10.1109/SURV.2013.100713.00203},
	abstract = {Machine-to-Machine (M2M) refers to technologies with various applications. In order to provide the vision and goals of M2M, an M2M ecosystem with a service platform must be established by the key players in industrial domains so as to substantially reduce development costs and improve time to market of M2M devices and services. The service platform must be supported by M2M enabling technologies and standardization. In this paper, we present a survey of existing M2M service platforms and explore the various research issues and challenges involved in enabling an M2M service platform. We first classify M2M nodes according to their characteristics and required functions, and we then highlight the features of M2M traffic. With these in mind, we discuss the necessity of M2M platforms. By comparing and analyzing the existing approaches and solutions of M2M platforms, we identify the requirements and functionalities of the ideal M2M service platform. Based on these, we propose an M2M service platform (M2SP) architecture and its functionalities, and present the M2M ecosystem with this platform. Different application scenarios are given to illustrate the interaction between the components of the proposed platform. In addition, we discuss the issues and challenges of enabling technologies and standardization activities, and outline future research directions for the M2M network.},
	number = {1},
	journal = {IEEE Communications Surveys \& Tutorials},
	author = {Kim, Jaewoo and Lee, Jaiyong and Kim, Jaeho and Yun, Jaeseok},
	year = {2014},
	note = {Conference Name: IEEE Communications Surveys \& Tutorials},
	keywords = {IP networks, Protocols, Business, Addressing, Architecture, Communication and Networking, Computer architecture, Ecosystems, Identification, Machine-to-Machine, Management, Peer-to-peer, Robot sensing systems, Service Platform, Standardization, Standards},
	pages = {61--76},
	file = {IEEE Xplore Abstract Record:/Users/damar.pramuditya/Zotero/storage/BFWD9GUK/6644332.html:text/html},
}

@misc{noauthor__nodate,
	title = {한국정보통신기술협회},
	url = {http://onem2mcert.com/},
	abstract = {한국정보통신기술협회,one M2M,M2m,oneM2M certified},
	language = {ko},
	urldate = {2023-04-27},
	file = {Snapshot:/Users/damar.pramuditya/Zotero/storage/E7BKVTIW/main.html:text/html},
}

@misc{saini_introduction_2021,
	title = {An {Introduction} to {Random} {Forest} {Algorithm} for beginners},
	url = {https://www.analyticsvidhya.com/blog/2021/10/an-introduction-to-random-forest-algorithm-for-beginners/},
	abstract = {Random forest are a supervised Machine learning algorithm that is widely used in regression and classification problems by data scientists},
	language = {en},
	urldate = {2023-04-23},
	journal = {Analytics Vidhya},
	author = {Saini, Anshul},
	month = oct,
	year = {2021},
	file = {Snapshot:/Users/damar.pramuditya/Zotero/storage/T2NJAG5V/an-introduction-to-random-forest-algorithm-for-beginners.html:text/html},
}

@article{alam_random_2013,
	title = {Random {Forest} {Classification} for {Detecting} {Android} {Malware}},
	doi = {10.1109/greencom-ithings-cpscom.2013.122},
	abstract = {Internet connected smartphone devices play a crucial role in the application domain of Internet of Things. These devices are being widely used for day-to-day activities such as remotely controlling lighting and heating at homes, paying for parking, and recently for paying for goods using saved credit card information using Near Field Communication (NFC). Android is the most popular smartphone platform today. It is also the choice of malware authors to obtain secure and private data. In this paper we exclusively apply the machine learning ensemble learning algorithm Random Forest supervised classifier on an Android feature dataset of 48919 points of 42 features each. Our goal was to measure the accuracy of Random Forest in classifying Android application behavior to classify applications as malicious or benign. Moreover, we wanted to focus on detection accuracy as the free parameters of the Random Forest algorithm such as the number of trees, depth of each tree and number of random features selected are varied. Our experimental results based on 5-fold cross validation of our dataset shows that Random Forest performs very well with an accuracy of over 99 percent in general, an optimal Out-Of-Bag (OOB) error rate [3] of 0.0002 for forests with 40 trees or more, and a root mean squared error of 0.0171 for 160 trees.},
	journal = {2013 IEEE International Conference on Green Computing and Communications and IEEE Internet of Things and IEEE Cyber, Physical and Social Computing},
	author = {Alam, Mohammed S. and Vuong, Son T.},
	month = aug,
	year = {2013},
	doi = {10.1109/greencom-ithings-cpscom.2013.122},
	note = {MAG ID: 2031254140
S2ID: 3b274b5e931c46819bedbe430eee99a3330c857d},
	pages = {663--669},
}

@article{speiser_comparison_2019,
	title = {A {Comparison} of {Random} {Forest} {Variable} {Selection} {Methods} for {Classification} {Prediction} {Modeling}.},
	volume = {134},
	doi = {10.1016/j.eswa.2019.05.028},
	abstract = {Abstract   Random forest classification is a popular machine learning method for developing prediction models in many research settings. Often in prediction modeling, a goal is to reduce the number of variables needed to obtain a prediction in order to reduce the burden of data collection and improve efficiency. Several variable selection methods exist for the setting of random forest classification; however, there is a paucity of literature to guide users as to which method may be preferable for different types of datasets. Using 311 classification datasets freely available online, we evaluate the prediction error rates, number of variables, computation times and area under the receiver operating curve for many random forest variable selection methods. We compare random forest variable selection methods for different types of datasets (datasets with binary outcomes, datasets with many predictors, and datasets with imbalanced outcomes) and for different types of methods (standard random forest versus conditional random forest methods and test based versus performance based methods). Based on our study, the best variable selection methods for most datasets are Jiang's method and the method implemented in the VSURF R package. For datasets with many predictors, the methods implemented in the R packages varSelRF and Boruta are preferable due to computational efficiency. A significant contribution of this study is the ability to assess different variable selection techniques in the setting of random forest classification in order to identify preferable methods based on applications in expert and intelligent systems.},
	journal = {Expert Systems With Applications},
	author = {Speiser, Jaime L. and Miller, Michael and Miller, Michael E. and Tooze, Janet A. and Ip, Edward H.},
	month = nov,
	year = {2019},
	doi = {10.1016/j.eswa.2019.05.028},
	pmid = {32968335},
	note = {MAG ID: 2944954104
S2ID: 67a9e2ecd5ff4188007d9de0d6a606ec864eb8c7},
	pages = {93--101},
}

@article{amorim_novelty_2019,
	title = {Novelty {Detection} in {Social} {Media} by {Fusing} {Text} and {Image} {Into} a {Single} {Structure}},
	volume = {7},
	doi = {10.1109/access.2019.2939736},
	abstract = {This work aims to propose an approach for detecting novelties, taking into account the temporal flow of data streams in social media. To this end, we present a completely new architecture for novelty detection. This new architecture entails three new contributions. First, we propose a new concept for novelty definition based on temporal windows. Second, we formulate an expression to determine the quality of a novelty. Third, we introduce a new approach to the fusion of heterogeneous data (image + text), using the COCO dataset and the MASK-RCNN convolutional neural network, which transforms image and text from social media into a single data format ready to be identified by machine learning algorithms. Since novelty detection is a task in which labeled samples are scarce or inexistent, unsupervised algorithms are used, and thus, the following baseline and state-of-the-art algorithms have been chosen: kNN, HBOS, FBagging, IForesting, and autoencoders. The new fusion approach is also compared to a state-of-the-art approach to outlier detection named AOM. Because of temporal particularities and the data types being fused, a new dataset was created, containing 27,494 tweets collected from Twitter. Our experiments show that data classification of social media using data fusion is superior to using only text or only images as input data.},
	journal = {IEEE Access},
	author = {Amorim, Marta and Bortoloti, Frederico Damasceno and Ciarelli, Patrick Marques and Salles, Evandro Ottoni Teatini and Cavalieri, Daniel Cruz},
	month = sep,
	year = {2019},
	doi = {10.1109/access.2019.2939736},
	note = {MAG ID: 2971882305
S2ID: 6aaa6234cd1ac807eb564ec5741b53b1d7d42de4},
	pages = {132786--132802},
}

@article{stephany_n_duda_hl7_2022,
	title = {{HL7} {FHIR}-based tools and initiatives to support clinical research: a scoping review},
	volume = {29},
	doi = {10.1093/jamia/ocac105},
	abstract = {Abstract Objectives The HL7® fast healthcare interoperability resources (FHIR®) specification has emerged as the leading interoperability standard for the exchange of healthcare data. We conducted a scoping review to identify trends and gaps in the use of FHIR for clinical research. Materials and methods We reviewed published literature, federally funded project databases, application websites, and other sources to discover FHIR-based papers, projects, and tools (collectively, “FHIR projects”) available to support clinical research activities. Results Our search identified 203 different FHIR projects applicable to clinical research. Most were associated with preparations to conduct research, such as data mapping to and from FHIR formats (n = 66, 32.5\%) and managing ontologies with FHIR (n = 30, 14.8\%), or post-study data activities, such as sharing data using repositories or registries (n = 24, 11.8\%), general research data sharing (n = 23, 11.3\%), and management of genomic data (n = 21, 10.3\%). With the exception of phenotyping (n = 19, 9.4\%), fewer FHIR-based projects focused on needs within the clinical research process itself. Discussion Funding and usage of FHIR-enabled solutions for research are expanding, but most projects appear focused on establishing data pipelines and linking clinical systems such as electronic health records, patient-facing data systems, and registries, possibly due to the relative newness of FHIR and the incentives for FHIR integration in health information systems. Fewer FHIR projects were associated with research-only activities. Conclusion The FHIR standard is becoming an essential component of the clinical research enterprise. To develop FHIR’s full potential for clinical research, funding and operational stakeholders should address gaps in FHIR-based research tools and methods.},
	number = {9},
	journal = {Journal of the American Medical Informatics Association},
	author = {{Stephany N Duda} and {Nan Kennedy} and {Douglas Conway} and Cheng, Alex and {Viet Nguyen} and {Teresa Zayas-Cabán} and {Paul A Harris}},
	month = jul,
	year = {2022},
	doi = {10.1093/jamia/ocac105},
	pmid = {35818340},
	note = {MAG ID: 4285021577
S2ID: 3b03bb73d5b381036b051a8f6885166733dafd28},
	pages = {1642--1653},
}

@article{mark_l_braunstein_fhir_2022,
	title = {{FHIR}},
	doi = {10.1007/978-3-030-91563-6_9},
	abstract = {In 2011, Australian HL7 standards guru, Grahame Grieve, proposed a new interoperability approach he called “Resources for Health (RFH)”. He said it would define a set of objects to represent granular clinical concepts for use on their own or aggregated into complex documents. As a result, it would be ‘composable’—so that, unlike with complex C-CDA documents, developers could request only the information needed for their particular use case. In part, because of that, he said that this flexibility could offer “coherent solutions for a range of interoperability problems”. Today, renamed Fast Healthcare Interoperability Resources (FHIR), Grahame’s approach is transforming virtually all aspects of health informatics. In this chapter we explore FHIR is detail.KeywordsFast healthcare interoperability resourcesFHIRFHIR resourcesFHIR APIFHIR profilesFHIR extensionsFHIR implementation guidesFHIRPathFHIR accelerators},
	journal = {Computers in health care},
	author = {{Mark L. Braunstein}},
	month = jan,
	year = {2022},
	doi = {10.1007/978-3-030-91563-6_9},
	note = {MAG ID: 4226475611
S2ID: 30019acc30c7d4e00d22b4dacece471c70bd18e8},
	pages = {233--291},
}

@article{rahat_tamjid_al_cerberus_2021,
	title = {Cerberus},
	doi = {10.1145/3548606.3559381},
	abstract = {OAuth protocols have been widely adopted to simplify user authentication and service authorization for third-party applications. However, little effort has been devoted to automatically checking the security of the libraries that service providers widely use. In this paper, we formalize the OAuth specifications and security best practices, and design Cerberus, an automated static analyzer, to find logical flaws and identify vulnerabilities in the implementation of OAuth service provider libraries. To efficiently detect security violations in a large codebase of service provider implementation, Cerberus employs a query-driven algorithm for answering queries about OAuth specifications. We demonstrate the effectiveness of Cerberus by evaluating it on datasets of popular OAuth libraries with millions of downloads. Among these high-profile libraries, Cerberus has identified 47 vulnerabilities from ten classes of logical flaws, 24 of which were previously unknown. We got acknowledged by the developers of eight libraries and had three accepted CVEs.},
	journal = {Cornell University - arXiv},
	author = {{Rahat, Tamjid Al} and {Feng, Yu} and {Tian, Yuan}},
	month = oct,
	year = {2021},
	doi = {10.1145/3548606.3559381},
	note = {ARXIV\_ID: 2110.01005
MAG ID: 4307533935
S2ID: f46ca6c03cf38891f8a04def46a1fa26aecc1a5b},
}

@inproceedings{agarwal_ask_2016,
	title = {Ask {Me} {Again} {But} {Don}'t {Annoy} {Me}: {Evaluating} {Re}-authentication {Strategies} for {Smartphones}},
	isbn = {978-1-931971-31-7},
	shorttitle = {Ask {Me} {Again} {But} {Don}'t {Annoy} {Me}},
	url = {https://www.usenix.org/conference/soups2016/technical-sessions/presentation/agarwal},
	language = {en},
	urldate = {2023-02-20},
	author = {Agarwal, Lalit and Khan, Hassan and Hengartner, Urs},
	year = {2016},
	pages = {221--236},
	file = {Full Text PDF:/Users/damar.pramuditya/Zotero/storage/U6JCZ4IV/Agarwal et al. - 2016 - Ask Me Again But Don't Annoy Me Evaluating Re-aut.pdf:application/pdf},
}

@article{khan_risk_2020,
	title = {Risk management in {Halal} supply chain: an integrated fuzzy {Delphi} and {DEMATEL} approach},
	volume = {16},
	issn = {1746-5664},
	shorttitle = {Risk management in {Halal} supply chain},
	url = {https://doi.org/10.1108/JM2-09-2019-0228},
	doi = {10.1108/JM2-09-2019-0228},
	abstract = {Purpose In a globalised environment, market volatility makes risk management an essential component of the supply chain. Similar to conventional supply chains, a Halal supply chain (HSC) is also affected by several factors making it vulnerable to risks. Therefore, the purpose of this study is to identify and analyse the elements of Halal supply chain management (HSCM) and their significant risk dimensions. Design/methodology/approach In total, 72 risk elements of HSCM are identified through a review of contemporary scientific literature along with news items and official websites related to risk management of conventional supply chain management, HSC and sustainable supply chain. Further, 42 risk elements are finalised using fuzzy Delphi and then these risk elements are categorised into 7 dimensions. The interrelationships among the risk dimensions as well as risk elements are developed using fuzzy DEMATEL. Findings Results suggest that production, planning, logistic \& outsourcing and information technology-related risk are prominent risk dimensions. The causal relationships among the significant risk dimensions and elements related to the HSCM may help managers and policy planners. Research limitations/implications This study faces a challenge due to inadequate availability of the literature related to risk management in the area of HSCM. Further, this study has used inputs from experts, which can be biased. Originality/value To the best of the author's knowledge, it is the first comprehensive study towards investigating the interrelationships among the risks in the context of the HSCM.},
	number = {1},
	urldate = {2023-02-20},
	journal = {Journal of Modelling in Management},
	author = {Khan, Shahbaz and Haleem, Abid and Khan, Mohd Imran},
	month = jan,
	year = {2020},
	note = {Publisher: Emerald Publishing Limited},
	keywords = {Fuzzy Delphi, Fuzzy DEMATEL, Halal supply chain management (HSCM), Risk, Risk management},
	pages = {172--214},
	file = {Full Text PDF:/Users/damar.pramuditya/Zotero/storage/HT3BVHPZ/Khan et al. - 2020 - Risk management in Halal supply chain an integrat.pdf:application/pdf},
}

@article{stephan_wiefling_whats_2021,
	title = {What's in {Score} for {Website} {Users}: {A} {Data}-driven {Long}-term {Study} on {Risk}-based {Authentication} {Characteristics}},
	doi = {10.1007/978-3-662-64331-0_19},
	journal = {Financial Cryptography},
	author = {{Stephan Wiefling} and {Markus Dürmuth} and {Luigi Lo Iacono}},
	year = {2021},
	doi = {10.1007/978-3-662-64331-0_19},
	note = {ARXIV\_ID: 2101.10681
S2ID: 2ea6241f8379f950bb2d91b1deab89123ef5680f},
	file = {Accepted Version:/Users/damar.pramuditya/Zotero/storage/N886RG9C/Stephan Wiefling et al. - 2021 - What's in Score for Website Users A Data-driven L.pdf:application/pdf},
}

@article{wiefling_is_2020,
	title = {Is {This} {Really} {You}? {An} {Empirical} {Study} on {Risk}-{Based} {Authentication} {Applied} in the {Wild}.},
	doi = {10.1007/978-3-030-22312-0_10},
	abstract = {Risk-based authentication (RBA) is an adaptive security measure to strengthen password-based authentication. RBA monitors additional implicit features during password entry such as device or geolocation information, and requests additional authentication factors if a certain risk level is detected. RBA is recommended by the NIST digital identity guidelines, is used by several large online services, and offers protection against security risks such as password database leaks, credential stuffing, insecure passwords and large-scale guessing attacks. Despite its relevance, the procedures used by RBA-instrumented online services are currently not disclosed. Consequently, there is little scientific research about RBA, slowing down progress and deeper understanding, making it harder for end users to understand the security provided by the services they use and trust, and hindering the widespread adoption of RBA. 
In this paper, with a series of studies on eight popular online services, we (i) analyze which features and combinations/classifiers are used and are useful in practical instances, (ii) develop a framework and a methodology to measure RBA in the wild, and (iii) survey and discuss the differences in the user interface for RBA. Following this, our work provides a first deeper understanding of practical RBA deployments and helps fostering further research in this direction.},
	journal = {arXiv: Cryptography and Security},
	author = {Wiefling, Stephan and Iacono, Luigi Lo and Dürmuth, Markus},
	year = {2020},
	doi = {10.1007/978-3-030-22312-0_10},
	note = {ARXIV\_ID: 2003.07622
MAG ID: 3100922535
S2ID: 5000c0087aef5cfa0d670bfef88abe38d1b23f03},
	file = {Submitted Version:/Users/damar.pramuditya/Zotero/storage/IHJBI5JH/Wiefling et al. - 2020 - Is This Really You An Empirical Study on Risk-Bas.pdf:application/pdf},
}

@article{taneja_analytics_2013,
	title = {An analytics framework to detect compromised {IoT} devices using mobility behavior},
	doi = {10.1109/ictc.2013.6675302},
	abstract = {Certain security mechanisms assume that the end device is secured. In an IoT network, the IoT device itself could be compromised. An attacker could steal the device, gain access to it and use this for more damaging attacks. I propose an analytical framework where I specify certain mobility behavior indicators that are computed at network nodes and optionally at IoT devices. These are communicated to an analytics server using lightweight protocol enhancements specified here. IoT user specifies expected behavior using these indicators. Analytics server analyzes expected and observed values of these indicators and informs if it detects some unusual activity.},
	journal = {Information and Communication Technology Convergence},
	author = {Taneja, Mukesh},
	month = dec,
	year = {2013},
	doi = {10.1109/ictc.2013.6675302},
	note = {MAG ID: 1992207658
S2ID: 738eb53e5da58684c1854f75406c45d22690df63},
	pages = {38--43},
	file = {taneja2013.pdf:C\:\\Users\\Damar\\Downloads\\taneja2013.pdf:application/pdf},
}

@article{roy_fuzzy_2018,
	title = {A fuzzy decision support system for multifactor authentication},
	volume = {22},
	doi = {10.1007/s00500-017-2607-6},
	abstract = {Multifactor authentication (MFA) is a growing trend for the accurate identification of the legitimate users through different modalities such as biometrics, nonbiometric, and cognitive behavior metric. In this paper, we have developed an adaptive MFA that considers the effects of different user devices, media, environments, and the frequency of authentication to detect the legitimate user. For this purpose, initially, we have evaluated the trustworthiness values of all the authentication modalities in different user devices and media using a nonlinear programming problem with probabilistic constraints. Finally, an evolutionary strategy, using fuzzy “IF–THEN” rule and genetic algorithm has been developed for the adaptive selection of authentication modalities. We have done a numerical simulation to prove the effectiveness and efficiency of the proposed method. Moreover, we have developed a prototype client–server-based application and have done a detailed user study to justify its better usability than the existing counterparts.},
	number = {12},
	journal = {Soft Computing - A Fusion of Foundations, Methodologies and Applications},
	author = {Roy, Arunava and Dasgupta, Dipankar},
	month = jun,
	year = {2018},
	doi = {10.1007/s00500-017-2607-6},
	note = {MAG ID: 2613668921
S2ID: bf2fe16da902e41a3530ababe5eb1a619dd3b501},
	pages = {3959--3981},
	file = {Roy and Dasgupta - 2018 - A fuzzy decision support system for multifactor au.pdf:/Users/damar.pramuditya/Zotero/storage/69HUUUGZ/Roy and Dasgupta - 2018 - A fuzzy decision support system for multifactor au.pdf:application/pdf},
}

@article{semenov_decision_2018,
	title = {Decision {Support} {System} {Based} on {FHIR} {Profiles}},
	volume = {249},
	doi = {10.3233/978-1-61499-868-6-117},
	abstract = {In some healthcare systems, it is common that patients address laboratory test centers directly without a doctor's referral. Russia is one of such countries with about 28\% of the patients going directly to the laboratory test center for diagnostics. This leads to a situation when patients are not supported by healthcare professionals in the interpretation of test results. Interpretation of test results is a resource-consuming task that will delay the results and increase costs of each test. However, this can be done by computer-based decision support systems that have proved to solve such tasks efficiently. So, the design and implementation of a decision support system that would generate reports for the patients who referred to a test center without a doctor's referral can increase motivation and support patients to make better informed decisions. The goal of this study is to implement a decision support system for patients. We developed a clinical decision support system for the patients that solves a classification problem by relating a vector of test results to a set of diagnoses and find a set of recommendations associated with every diagnosis from this set.},
	journal = {Studies in health technology and informatics},
	author = {Semenov, Ilia and Kopanitsa, Georgy},
	month = jan,
	year = {2018},
	doi = {10.3233/978-1-61499-868-6-117},
	pmid = {29866966},
	note = {MAG ID: 2810571226
S2ID: 9c77eb59457bf95b8db75ad30059b96360afb060},
	pages = {117--121},
}

@article{dutson_dont_2019,
	title = {Don't {Punish} all of us: {Measuring} {User} {Attitudes} about {Two}-{Factor} {Authentication}},
	doi = {10.1109/eurospw.2019.00020},
	abstract = {Two-factor authentication (2FA) defends against password compromise by a remote attacker. We surveyed 4,275 students, faculty, and staff at Brigham Young University to measure user sentiment about Duo 2FA one year after the university adopted it. The results were mixed. A majority of the participants felt more secure using Duo and felt it was easy to use. About half of all participants reported at least one instance of being locked out of their university account because of an inability to authenticate with Duo. We found that students and faculty generally had more negative perceptions of Duo than staff. The survey responses reveal some pain points for Duo users. In response, we offer recommendations that reduce the frequency of 2FA for users. We also suggest UI changes that draw more attention to 2FA methods that do not require WiFi, the "Remember Me" setting, and the help utility.},
	author = {Dutson, Jonathan and Allen, Danny and Eggett, Dennis L. and Seamons, Kent E.},
	month = jun,
	year = {2019},
	doi = {10.1109/eurospw.2019.00020},
	note = {MAG ID: 2969468676},
	pages = {119--128},
}

@article{thomas_data_2017,
	title = {Data {Breaches}, {Phishing}, or {Malware}?: {Understanding} the {Risks} of {Stolen} {Credentials}},
	doi = {10.1145/3133956.3134067},
	abstract = {In this paper, we present the first longitudinal measurement study of the underground ecosystem fueling credential theft and assess the risk it poses to millions of users. Over the course of March, 2016--March, 2017, we identify 788,000 potential victims of off-the-shelf keyloggers; 12.4 million potential victims of phishing kits; and 1.9 billion usernames and passwords exposed via data breaches and traded on blackmarket forums. Using this dataset, we explore to what degree the stolen passwords---which originate from thousands of online services---enable an attacker to obtain a victim's valid email credentials---and thus complete control of their online identity due to transitive trust. Drawing upon Google as a case study, we find 7--25\% of exposed passwords match a victim's Google account. For these accounts, we show how hardening authentication mechanisms to include additional risk signals such as a user's historical geolocations and device profiles helps to mitigate the risk of hijacking. Beyond these risk metrics, we delve into the global reach of the miscreants involved in credential theft and the blackhat tools they rely on. We observe a remarkable lack of external pressure on bad actors, with phishing kit playbooks and keylogger capabilities remaining largely unchanged since the mid-2000s.},
	author = {Thomas, Kurt and Li, Frank and Zand, Ali and Barrett, Jacob and Ranieri, Juri and Invernizzi, Luca and Markov, Yarik and Comanescu, Oxana and Eranti, Vijay and Moscicki, Angelika and Margolis, Daniel and Paxson, Vern and Bursztein, Elie},
	month = oct,
	year = {2017},
	doi = {10.1145/3133956.3134067},
	note = {MAG ID: 2765227388},
	pages = {1421--1434},
	file = {Full Text:/Users/damar.pramuditya/Zotero/storage/F55ZU28S/Thomas et al. - 2017 - Data Breaches, Phishing, or Malware Understandin.pdf:application/pdf},
}

@article{rivera_risk-based_2020,
	title = {Risk-based {Authentication} {Based} on {Network} {Latency} {Profiling}},
	doi = {10.1145/3411508.3421377},
	abstract = {Impersonation attacks against web authentication servers have been increasing in complexity over the last decade. Tunnelling services, such as VPNs or proxies, can be for instance used to faithfully impersonate victims in foreign countries. In this paper we study the detection of user authentication attacks involving network tunnelling geolocation deception. For that purpose we explore different models to profile a user based on network latencies. We design a classical machine learning model and a deep learning model to profile web resource loading times collected on client-side. In order to test our approach we profiled network latencies for 86 real users located around the globe. We show that our proposed novel network profiling is able to detect up to 88.3\% of attacks using VPN tunneling schemes},
	author = {Rivera, Esteban and Tengana, Lizzy and Solano, Jesus and Castelblanco, Alejandra and Lopez, Christian and Ochoa, Martín},
	year = {2020},
	doi = {10.1145/3411508.3421377},
	note = {MAG ID: 3097029392},
	file = {Rivera et al. - 2020 - Risk-based Authentication Based on Network Latency.pdf:/Users/damar.pramuditya/Zotero/storage/5XTG28M3/Rivera et al. - 2020 - Risk-based Authentication Based on Network Latency.pdf:application/pdf},
}

@article{doerfler_evaluating_2019,
	title = {Evaluating {Login} {Challenges} as {aDefense} {Against} {Account} {Takeover}},
	doi = {10.1145/3308558.3313481},
	abstract = {In this paper, we study the efficacy of login challenges at preventing account takeover, as well as evaluate the amount of friction these challenges create for normal users. These secondary authentication factors-presently deployed at Google, Microsoft, and other major identity providers as part of risk-aware authentication-trigger in response to a suspicious login or account recovery attempt. Using Google as a case study, we evaluate the effectiveness of fourteen device-based, delegation-based, knowledge-based, and resource-based challenges at preventing over 350,000 real-world hijacking attempts stemming from automated bots, phishers, and targeted attackers. We show that knowledge-based challenges prevent as few as 10\% of hijacking attempts rooted in phishing and 73\% of automated hijacking attempts. Device-based challenges provide the best protection, blocking over 94\% of hijacking attempts rooted in phishing and 100\% of automated hijacking attempts. We evaluate the usability limitations of each challenge based on a sample of 1.2M legitimate users. Our results illustrate that login challenges act as an important barrier to hijacking, but that friction in the process leads to 52\% of legitimate users failing to sign-in-though 97\% of users eventually access their account in a short period.},
	author = {Doerfler, Periwinkle and Thomas, Kurt and Marincenko, Maija and Ranieri, Juri and Jiang, Yu and Moscicki, Angelika and McCoy, Damon},
	month = may,
	year = {2019},
	doi = {10.1145/3308558.3313481},
	note = {MAG ID: 2914845368},
	pages = {372--382},
}

@article{gruendner_integrating_2020,
	title = {Integrating {Genomics} and {Clinical} {Data} for {Statistical} {Analysis} by {Using} {GEnome} {MINIng} ({GEMINI}) and {Fast} {Healthcare} {Interoperability} {Resources} ({FHIR}): {System} {Design} and {Implementation}.},
	volume = {22},
	doi = {10.2196/19879},
	abstract = {BACKGROUND The introduction of next-generation sequencing (NGS) into molecular cancer diagnostics has led to an increase in the data available for the identification and evaluation of driver mutations and for defining personalized cancer treatment regimens. The meaningful combination of omics data, ie, pathogenic gene variants and alterations with other patient data, to understand the full picture of malignancy has been challenging. OBJECTIVE This study describes the implementation of a system capable of processing, analyzing, and subsequently combining NGS data with other clinical patient data for analysis within and across institutions. METHODS On the basis of the already existing NGS analysis workflows for the identification of malignant gene variants at the Institute of Pathology of the University Hospital Erlangen, we defined basic requirements on an NGS processing and analysis pipeline and implemented a pipeline based on the GEMINI (GEnome MINIng) open source genetic variation database. For the purpose of validation, this pipeline was applied to data from the 1000 Genomes Project and subsequently to NGS data derived from 206 patients of a local hospital. We further integrated the pipeline into existing structures of data integration centers at the University Hospital Erlangen and combined NGS data with local nongenomic patient-derived data available in Fast Healthcare Interoperability Resources format. RESULTS Using data from the 1000 Genomes Project and from the patient cohort as input, the implemented system produced the same results as already established methodologies. Further, it satisfied all our identified requirements and was successfully integrated into the existing infrastructure. Finally, we showed in an exemplary analysis how the data could be quickly loaded into and analyzed in KETOS, a web-based analysis platform for statistical analysis and clinical decision support. CONCLUSIONS This study demonstrates that the GEMINI open source database can be augmented to create an NGS analysis pipeline. The pipeline generates high-quality results consistent with the already established workflows for gene variant annotation and pathological evaluation. We further demonstrate how NGS-derived genomic and other clinical data can be combined for further statistical analysis, thereby providing for data integration using standardized vocabularies and methods. Finally, we demonstrate the feasibility of the pipeline integration into hospital workflows by providing an exemplary integration into the data integration center infrastructure, which is currently being established across Germany.},
	number = {10},
	journal = {Journal of Medical Internet Research},
	author = {Gruendner, Julian and Wolf, Nicolas and Tögel, Lars and Tögel, Lars and Haller, Florian and Prokosch, Hans-Ulrich and Christoph, Jan},
	year = {2020},
	doi = {10.2196/19879},
	pmcid = {7578821},
	pmid = {33026356},
	note = {MAG ID: 3092308791
S2ID: 833bf49b3cc99ea8d87d81feb208e01e8b3f82ee},
	file = {Full Text:/Users/damar.pramuditya/Zotero/storage/985EA9BX/Gruendner et al. - 2020 - Integrating Genomics and Clinical Data for Statist.pdf:application/pdf},
}

@article{gruendner_ketos_2019,
	title = {{KETOS}: {Clinical} decision support and machine learning as a service ─ {A} training and deployment platform based on {Docker}, {OMOP}-{CDM}, and {FHIR} {Web} {Services}},
	volume = {14},
	doi = {10.1371/journal.pone.0223010},
	abstract = {Background and objective 
To take full advantage of decision support, machine learning, and patient-level prediction models, it is important that models are not only created, but also deployed in a clinical setting. The KETOS platform demonstrated in this work implements a tool for researchers allowing them to perform statistical analyses and deploy resulting models in a secure environment.


Methods 
The proposed system uses Docker virtualization to provide researchers with reproducible data analysis and development environments, accessible via Jupyter Notebook, to perform statistical analysis and develop, train and deploy models based on standardized input data. The platform is built in a modular fashion and interfaces with web services using the Health Level 7 (HL7) Fast Healthcare Interoperability Resources (FHIR) standard to access patient data. In our prototypical implementation we use an OMOP common data model (OMOP-CDM) database. The architecture supports the entire research lifecycle from creating a data analysis environment, retrieving data, and training to final deployment in a hospital setting.


Results 
We evaluated the platform by establishing and deploying an analysis and end user application for hemoglobin reference intervals within the University Hospital Erlangen. To demonstrate the potential of the system to deploy arbitrary models, we loaded a colorectal cancer dataset into an OMOP database and built machine learning models to predict patient outcomes and made them available via a web service. We demonstrated both the integration with FHIR as well as an example end user application. Finally, we integrated the platform with the open source DataSHIELD architecture to allow for distributed privacy preserving data analysis and training across networks of hospitals.


Conclusion 
The KETOS platform takes a novel approach to data analysis, training and deploying decision support models in a hospital or healthcare setting. It does so in a secure and privacy-preserving manner, combining the flexibility of Docker virtualization with the advantages of standardized vocabularies, a widely applied database schema (OMOP-CDM), and a standardized way to exchange medical data (FHIR).},
	number = {10},
	journal = {PLOS ONE},
	author = {Gruendner, Julian and Schwachhofer, Thorsten and Sippl, Phillip and Wolf, Nicolas and Erpenbeck, Marcel and Gulden, Christian and Kapsner, Lorenz A. and Zierk, Jakob and Mate, Sebastian and Stürzl, Michael and Croner, Roland S. and Prokosch, Hans-Ulrich and Toddenroth, Dennis},
	month = oct,
	year = {2019},
	doi = {10.1371/journal.pone.0223010},
	pmcid = {6776354},
	pmid = {31581246},
	note = {MAG ID: 2977456252
S2ID: 3632674890abeba561af514d880a46400734f90b},
	file = {Full Text:/Users/damar.pramuditya/Zotero/storage/5BLLUY8W/Gruendner et al. - 2019 - KETOS Clinical decision support and machine learn.pdf:application/pdf},
}

@article{stephan_wiefling_pump_2022,
	title = {Pump {Up} {Password} {Security}! {Evaluating} and {Enhancing} {Risk}-{Based} {Authentication} on a {Real}-{World} {Large}-{Scale} {Online} {Service}},
	doi = {10.1145/3546069},
	abstract = {Risk-based authentication (RBA) aims to protect users against attacks involving stolen passwords. RBA monitors features during login, and requests re-authentication when feature values widely differ from previously observed ones. It is recommended by various national security organizations, and users perceive it more usable and equally secure than equivalent two-factor authentication. Despite that, RBA is still only used by very few online services. Reasons for this include a lack of validated open resources on RBA properties, implementation, and configuration. This effectively hinders the RBA research, development, and adoption progress. To close this gap, we provide the first long-term RBA analysis on a real-world large-scale online service. We collected feature data of 3.3 million users and 31.3 million login attempts over more than one year. Based on the data, we provide (i) studies on RBA’s real-world characteristics, and its configurations and enhancements to balance usability, security, and privacy, (ii) a machine learning based RBA parameter optimization method to support administrators finding an optimal configuration for their own use case scenario, (iii) an evaluation of the round-trip time feature’s potential to replace the IP address for enhanced user privacy, and (iv) a synthesized RBA data set to reproduce this research and to foster future RBA research. Our results provide insights on selecting an optimized RBA configuration so that users profit from RBA after just a few logins. The open data set enables researchers to study, test, and improve RBA for widespread deployment in the wild.},
	journal = {ACM transactions on privacy and security},
	author = {{Stephan Wiefling} and {Paul René Jørgensen} and {Sigurd Thunem} and {Luigi Lo Iacono}},
	month = jun,
	year = {2022},
	doi = {10.1145/3546069},
	note = {ARXIV\_ID: 2206.15139
MAG ID: 4283724392
S2ID: 9166596f4e27d39728a8f80f0c2aa35b20095c10},
	file = {Full Text:/Users/damar.pramuditya/Zotero/storage/CF2VZ8JL/Stephan Wiefling et al. - 2022 - Pump Up Password Security! Evaluating and Enhancin.pdf:application/pdf},
}

@article{jain_who_2016,
	title = {Who are you? {A} statistical approach to measuring user authenticity},
	doi = {10.14722/ndss.2016.23240},
	abstract = {Passwords are used for user authentication by almost every Internet service today, despite a number of wellknown weaknesses. Numerous attempts to replace passwords have failed, in part because changing users’ behavior has proven to be difficult. One approach to strengthening password-based authentication without changing user experience is to classify login attempts into normal and suspicious activity based on a number of parameters such as source IP, geo-location, browser configuration, and time of day. For the suspicious attempts, the service can then require additional verification, e.g., by an additional phone-based authentication step. Systems working along these principles have been deployed by a number of Internet services but have never been studied publicly. In this work, we perform the first public evaluation of a classification system for user authentication. In particular: (i) We develop a statistical framework for identifying suspicious login attempts. (ii) We develop a fully functional prototype implementation that can be evaluated efficiently on large datasets. (iii) We validate our system on a sample of real-life login data from LinkedIn as well as simulated attacks, and demonstrate that a majority of attacks can be prevented by imposing additional verification steps on only a small fraction of users. (iv) We provide a systematic study of possible attackers against such a system, including attackers targeting the classifier itself.},
	journal = {Network and Distributed System Security Symposium},
	author = {Jain, Sakshi and {S Jain} and Freeman, M Mandell and Biggio, Battista and Duermuth, M and Giacinto, Giorgio},
	month = jan,
	year = {2016},
	doi = {10.14722/ndss.2016.23240},
	note = {MAG ID: 2396652156
S2ID: f9555252c1e076e803e6e4f389cd230e06aacb8d},
	file = {Full Text:/Users/damar.pramuditya/Zotero/storage/JX7WSB2S/Jain et al. - 2016 - Who are you A statistical approach to measuring u.pdf:application/pdf},
}

@article{steinegger_risk-based_2016,
	title = {Risk-based authenticator for web applications},
	doi = {10.1145/3011784.3011800},
	abstract = {Web applications for consumers often require authenticated users in order to offer their services. In this context, consumers expect authentication to be easy to use and their resources to be secured properly. But, authentication in web applications is often vulnerable, e.g., passwords can be stolen, fingerprints can be imitated or the authentication protocol implementation may have a security flaw. Several best practices solving this problem evolved in several web applications. We analyzed such solutions that continuously and transparently collect data on the user to learn their typical behavior and detect anomalies. Based on this analysis, we describe the security pattern risk-based authenticator and exemplify its application in the SmartCampus, a service-oriented web application.},
	author = {Steinegger, Roland H. and Deckers, Daniel and Giessler, Pascal and Abeck, Sebastian},
	month = jul,
	year = {2016},
	doi = {10.1145/3011784.3011800},
	note = {MAG ID: 2589105923},
	pages = {16},
}

@article{alaca_device_2016,
	title = {Device fingerprinting for augmenting web authentication: classification and analysis of methods},
	doi = {10.1145/2991079.2991091},
	abstract = {Device fingerprinting is commonly used for tracking users. We explore device fingerprinting but in the specific context of use for augmenting authentication, providing a state-of-the-art view and analysis. We summarize and classify 29 available methods and their properties; define attack models relevant to augmenting passwords for user authentication; and qualitatively compare them based on stability, repeatability, resource use, client passiveness, difficulty of spoofing, and distinguishability offered.},
	author = {Alaca, Furkan and van Oorschot, P. C.},
	month = dec,
	year = {2016},
	doi = {10.1145/2991079.2991091},
	note = {MAG ID: 2559753054},
	pages = {289--301},
}

@article{pal_beyond_2019,
	title = {Beyond {Credential} {Stuffing}: {Password} {Similarity} {Models} {Using} {Neural} {Networks}},
	doi = {10.1109/sp.2019.00056},
	abstract = {Attackers increasingly use passwords leaked from one website to compromise associated accounts on other websites. Such targeted attacks work because users reuse, or pick similar, passwords for different websites. We recast one of the core technical challenges underlying targeted attacks as the task of modeling similarity of human-chosen passwords. We show how to learn good password similarity models using a compilation of 1.4 billion leaked email, password pairs. Using our trained models of password similarity, we exhibit the most damaging targeted attack to date. Simulations indicate that our attack compromises more than 16\% of user accounts in less than a thousand guesses, should one of their other passwords be known to the attacker and despite the use of state-of-the art countermeasures. We show via a case study involving a large university authentication service that the attacks are also effective in practice. We go on to propose the first-ever defense against such targeted attacks, by way of personalized password strength meters (PPSMs). These are password strength meters that can warn users when they are picking passwords that are vulnerable to attacks, including targeted ones that take advantage of the user’s previously compromised passwords. We design and build a PPSM that can be compressed to less than 3 MB, making it easy to deploy in order to accurately estimate the strength of a password against all known guessing attacks.},
	author = {Pal, Bijeeta and Daniel, Tal and {Tal Daniel} and Chatterjee, R. and Chatterjee, Rahul and Ristenpart, Thomas},
	month = apr,
	year = {2019},
	doi = {10.1109/sp.2019.00056},
	note = {MAG ID: 2931153881},
	pages = {417--434},
	file = {Full Text:/Users/damar.pramuditya/Zotero/storage/S9HKILHZ/Pal et al. - 2019 - Beyond Credential Stuffing Password Similarity Mo.pdf:application/pdf},
}

@article{munonye_machine_2021,
	title = {Machine learning approach to vulnerability detection in {OAuth} 2.0 authentication and authorization flow},
	doi = {10.1007/s10207-021-00551-w},
	abstract = {Technologies for integrating enterprise web applications have improved rapidly over the years. The OAuth framework provides authentication and authorization using the users’ profile and credentials in an existing identity provider. This makes it possible for attackers to exploit any vulnerability arising from exchange of data with the provider. Vulnerability in OAuth authorization flow allows an attacker to alter the normal flow sequence of the OAuth protocol. In this paper, a machine learning-based approach was applied in the detection of potential vulnerability in the OAuth authentication and authorization flow by analyzing the relationship between changes in the OAuth parameters and the final output. This research models the OAuth protocol as a supervised learning problem where seven classification models were developed, tuned and evaluated. Exploratory Data Analytics (EDA) techniques were applied in the extraction and analysis of specific OAuth features so that each output class could be evaluated to determine the effect of the identified OAuth features. The models developed in this research were trained, tuned and tested. A performance accuracy above 90\% was attained for detection of vulnerabilities in the OAuth authentication and authorization flow. Comparison with known vulnerability resulted in a 54\% match.},
	journal = {International Journal of Information Security},
	author = {Munonye, Kindson and Péter, Martinek},
	month = may,
	year = {2021},
	doi = {10.1007/s10207-021-00551-w},
	note = {MAG ID: 3162806222
S2ID: b96815f099996126175ff302f367c3b8fcb5955f},
	pages = {1--15},
	file = {Full Text:/Users/damar.pramuditya/Zotero/storage/V7NFQKVN/Munonye and Péter - 2021 - Machine learning approach to vulnerability detecti.pdf:application/pdf},
}

@article{zhang_location-based_2012,
	title = {Location-{Based} {Authentication} and {Authorization} {Using} {Smart} {Phones}},
	doi = {10.1109/trustcom.2012.198},
	abstract = {Authentication and authorization are two of the most important security features for mobile transaction systems. Most commonly, these schemes depend on three factors: what you know (secret), what you have (token), and what you are (biometrics). In this paper, we propose a location-based authentication and authorization scheme for mobile transactions using smart phones. The paper first describes the distinguished features and the architecture of our proposed solution. Second, the core of our design, including three parts: location registration, authentication and authorization as well as location verification, are described.},
	journal = {2012 IEEE 11th International Conference on Trust, Security and Privacy in Computing and Communications},
	author = {Zhang, Feng and Kondoro, Aron and Muftic, Sead},
	month = jun,
	year = {2012},
	doi = {10.1109/trustcom.2012.198},
	note = {MAG ID: 2134348919
S2ID: b854f83ab609af8ac44c08e92a98a61fd84090ce},
	pages = {1285--1292},
	file = {Submitted Version:/Users/damar.pramuditya/Zotero/storage/39CCQ5T4/Zhang et al. - 2012 - Location-Based Authentication and Authorization Us.pdf:application/pdf},
}

@article{prasad_study_2017,
	title = {A {Study} on {Enhancing} {Mobile} {Banking} {Services} {Using} {Location} {Based} {Authentication}},
	doi = {10.47992/ijmts.2581.6012.0006},
	abstract = {Every now and then mobile users are increasing in exponentially all over the world, which leads to the growth of mobile-enabled services like mobile banking. The smart phone now available in the market having the ability to do all the functions that people can do olden days using their personal computers. The introduction of mobile communication technology modernization, innovation and globalization are increasingly driving the banking services to become ubiquitous, personalized, convenience, disseminative and secured. Mobile Banking Authentication has evolved over time to include several parameters such as Biometric, Location, Context, History, Profile etc. In this paper, we discuss new mobile banking services like Digital deposit apps, advanced bill payment apps, and Electronic meeting for mini loan services and Mobile payment apps. We can provide higher security for these new services through an intelligent multi-modal Authentication with Location Awareness. Here the location, where the mobile banking transaction has been executed is captured giving the additional option for a Bank to verify if the transaction has been executed normally or if the parameters are at variance with normal practice. If the Location happens to be very in a different country, an additional verification process can be introduced adding to the entropy of Authentication. If the Location happens to be a Bank Branch or an ATM, where there is a proper iBeacon or GPS providing additional information about identification, then in such a situation the Authentication can be further simplified based on the type of transaction. In this paper, we discuss in detail location based authentication and how these can be effectively applied in enhancing the mobile banking services.},
	author = {Prasad, K. Krishna and K, Krishna Prasad and Aithal, Sreeramana},
	month = may,
	year = {2017},
	doi = {10.47992/ijmts.2581.6012.0006},
	note = {MAG ID: 2619119693
S2ID: fd10b17cfe4ead0d2551438a1dadcf8b1f06fd68},
	file = {Full Text:/Users/damar.pramuditya/Zotero/storage/KMCKTVVK/Prasad et al. - 2017 - A Study on Enhancing Mobile Banking Services Using.pdf:application/pdf},
}

@article{a_poonguzhali_authorization_2022,
	title = {Authorization {Method} of {Control} in {Android} {Application} {Using} {Adminio} with {Context}-{Based} {Access} {Devices}},
	doi = {10.1109/icsss54381.2022.9782204},
	abstract = {Students could be permitted in using smart phones with context-based handset policy initiatives as they can deactivate those application areas using the camera as well as any handset assets and permissions which students constrain while being in class, whereas the user device could indeed retain all of its original permissions outside of the workplace. Once an app has indeed been granted the required permissions upon deployment, an Android user has no command over its functionality. So, by using cbac mechanism, a new prototype has been initiated on Android, namely Adminio. Adminio app features the control over the access mechanism of the user within gps location. It tracks down the user apps and the admin can able to restrict the user to use the mobile apps within the location. By using certain privileged policies, the admin controls the user such as blocking it. Even after uninstallation, the detach IP can be identified.},
	journal = {2022 8th International Conference on Smart Structures and Systems (ICSSS)},
	author = {{A. Poonguzhali} and {G. Premalatha} and {A. Abinaya} and {R. Thiagarajan} and {R. Krishnamoorthy} and {S. Arun}},
	month = apr,
	year = {2022},
	doi = {10.1109/icsss54381.2022.9782204},
	note = {MAG ID: 4281642317
S2ID: 88ef496c22321bd328d4ad0c13183c4c274b111f},
	file = {A. Poonguzhali et al. - 2022 - Authorization Method of Control in Android Applica.pdf:/Users/damar.pramuditya/Zotero/storage/B897MB99/A. Poonguzhali et al. - 2022 - Authorization Method of Control in Android Applica.pdf:application/pdf},
}

@article{cabarcos_survey_2019,
	title = {A {Survey} on {Adaptive} {Authentication}},
	volume = {52},
	doi = {10.1145/3336117},
	abstract = {Adaptive Authentication allows a system to dynamically select the best mechanism(s) for authenticating a user depending on contextual factors, such as location, proximity to devices, and other attributes. Though this technology has the potential to change the current password-dominated authentication landscape, research to date has not led to practical solutions that transcend to our daily lives. Motivated to find out how to improve adaptive authentication design, we provide a structured survey of the existing literature to date and analyze it to identify and discuss current research challenges and future directions.},
	number = {4},
	journal = {ACM Computing Surveys},
	author = {Cabarcos, Patricia Arias and Arias-Cabarcos, Patricia and Krupitzer, Christian and Becker, Christian},
	month = sep,
	year = {2019},
	doi = {10.1145/3336117},
	note = {MAG ID: 2953371218},
	pages = {80},
	file = {10.1145@3336117.pdf:C\:\\Users\\Damar\\Downloads\\10.1145@3336117.pdf:application/pdf},
}

@article{misbahuddin_design_2017,
	title = {Design of a risk based authentication system using machine learning techniques},
	doi = {10.1109/uic-atc.2017.8397628},
	abstract = {Authentication provides a means to verify the legitimacy of a user trying to access any confidential or sensitive information. The need for protecting secure data hosted on the web has been rising exponentially as organizations are moving their applications online. Static methods of authentication cannot completely guarantee the genuineness of a user. This has led to the development of multi-factor authentication systems. Riskbased authentication, a form of multi factor authentication adapts itself according to the risk profile of the users. This paper puts forth the design of risk engine integrated with the system to examine the user's past login records and generate a suitable pattern using machine learning algorithms to calculate the risk level of the user. The risk level further decides the authentication method that the user will be challenged with. Thus the adaptive authentication model helps in providing a higher level of security to its users.},
	author = {Misbahuddin, Mohammed and {B. S. Bindhumadhava} and {B. S. Bindhumadhava} and Bindhumadhava, B. S. and Dheeptha, B.},
	month = aug,
	year = {2017},
	doi = {10.1109/uic-atc.2017.8397628},
	note = {MAG ID: 2810458423},
	pages = {1--6},
	file = {misbahuddin2017.pdf:D\:\\Documents\\misbahuddin2017.pdf:application/pdf},
}

@article{alejandro_g_martin_approach_2021,
	title = {An approach to detect user behaviour anomalies within identity federations},
	volume = {108},
	doi = {10.1016/j.cose.2021.102356},
	abstract = {Abstract   User and Entity Behaviour Analytics (UEBA) mechanisms rely on statistical techniques and Machine Learning to determine when a significant deviation from patterns or trends established as a standard for users and entities is occurring. These mechanisms are beneficial within cybersecurity contexts because they allow managers and administrators to have early alerts warning about potential security incidents. This paper proposes the utilisation of UEBA to improve the security of Federated Identity Management (FIM) solutions. The proposed UEBA workflow allows Relying Parties within identity federations to build a session fingerprint characterising each user’s behaviour from available information. Furthermore, it enables anomaly detection based on this fingerprint, integrating raised alerts within current identity management specifications. The proposed workflow is validated and evaluated in a real use case based on a web chat application using OpenID Connect for identity management.},
	journal = {Computers \& Security},
	author = {{Alejandro G. Martín} and Martín, Alejandro and Beltrán, Marta and Fernández-Isabel, Alberto and de Diego, Isaac Martín},
	month = jun,
	year = {2021},
	doi = {10.1016/j.cose.2021.102356},
	note = {MAG ID: 3169815615},
	pages = {102356},
	file = {Full Text:/Users/damar.pramuditya/Zotero/storage/X4KP8FEX/Alejandro G. Martín et al. - 2021 - An approach to detect user behaviour anomalies wit.pdf:application/pdf},
}

@article{abu_bakar_adaptive_2014,
	title = {Adaptive authentication based on analysis of user behavior},
	doi = {10.1109/sai.2014.6918248},
	abstract = {Authentication is a mechanism to verify identity of users. Those who can present valid credential are considered as authenticated identities. In this paper, we introduce an adaptive authentication system called Unified Authentication Platform (UAP) which incorporates adaptive control to identify high-risk and suspicious illegitimate login attempts. The system evaluates comprehensive set of known information about the users from the past login history to define their normal behavior profile. The system leverages this information that has been previously stored to determine the security risk and level of assurance of current login attempt.},
	journal = {Sai},
	author = {Abu Bakar, Khairul Azmi and Haron, Galoh Rashidah},
	month = jan,
	year = {2014},
	doi = {10.1109/sai.2014.6918248},
	note = {MAG ID: 2313982364
S2ID: be198e510d1927281abbe8d4e83bad1bd0b8e861},
	pages = {601--606},
}

@article{solapurkar_building_2016,
	title = {Building secure healthcare services using {OAuth} 2.0 and {JSON} web token in {IOT} cloud scenario},
	doi = {10.1109/ic3i.2016.7917942},
	abstract = {OAuth 2.0 is a delegated authorization framework enabling secure authorization for applications running on various kinds of platforms. In healthcare services, OAuth allows the patient (resource owner) seeking real time clinical care to authorize automatic monthly payments from his bank account (resource server) without the patient being required to supply his credentials to the clinic (client app). OAuth 2.0 achieves this with the help of tokens issued by an authorization server which enables validated access to a protected resource. To ensure security, access tokens have an expiry time and are short-lived. So the clinical app may use a refresh token to obtain a new access token to cash monthly payments for rendering real time health care services. Refresh tokens need secure storage to ensure they are not leaked, since any malicious party can use them to obtain new access and refresh tokens. Since OAuth 2.0 has dropped signatures and relies completely on SSL/TLS, it is vulnerable to phishing attack when accessing interoperable APIs. In this paper, we develop an approach that combines JSON web token (JWT) with OAuth 2.0 to request an OAuth access token from authorization server when a client wishes to utilize a previous authentication and authorization. Experimental evaluation confirms that the proposed scheme is practically efficient, removes secure storage overhead by removing the need to have or store refresh token, uses signature and prevents different security attacks which is highly desired in health care services using an IOT cloud platform.},
	journal = {International Conferences on Contemporary Computing and Informatics},
	author = {Solapurkar, Prajakta},
	month = dec,
	year = {2016},
	doi = {10.1109/ic3i.2016.7917942},
	note = {MAG ID: 2611046206
S2ID: cedc874c8592d1336c07efb9393b93acd34b36c4},
	pages = {99--104},
}

@article{wagholikar_smart--fhir_2017,
	title = {{SMART}-on-{FHIR} implemented over i2b2.},
	volume = {24},
	doi = {10.1093/jamia/ocw079},
	abstract = {We have developed an interface to serve patient data from Informatics for Integrating Biology and the Bedside (i2b2) repositories in the Fast Healthcare Interoperability Resources (FHIR) format, referred to as a SMART-on-FHIR cell. The cell serves FHIR resources on a per-patient basis, and supports the “substitutable” modular third-party applications (SMART) OAuth2 specification for authorization of client applications. It is implemented as an i2b2 server plug-in, consisting of 6 modules: authentication, REST, i2b2-to-FHIR converter, resource enrichment, query engine, and cache. The source code is freely available as open source. We tested the cell by accessing resources from a test i2b2 installation, demonstrating that a SMART app can be launched from the cell that accesses patient data stored in i2b2. We successfully retrieved demographics, medications, labs, and diagnoses for test patients. The SMART-on-FHIR cell will enable i2b2 sites to provide simplified but secure data access in FHIR format, and will spur innovation and interoperability . Further, it transforms i2b2 into an apps platform.},
	number = {2},
	journal = {Journal of the American Medical Informatics Association},
	author = {Wagholikar, Kavishwar B. and Mandel, Joshua C. and Klann, Jeffery G. and Wattanasin, Nich and {Michael Mendis} and Mendis, Michael and Chute, Christopher G. and Mandl, Kenneth D. and Murphy, Shawn N.},
	month = mar,
	year = {2017},
	doi = {10.1093/jamia/ocw079},
	pmcid = {5391721},
	pmid = {27274012},
	note = {MAG ID: 2418573010
S2ID: ee535a5d96b965147d5d6f378ce277935d28536d},
	pages = {398--402},
	file = {Full Text:/Users/damar.pramuditya/Zotero/storage/TRUMPSSL/Wagholikar et al. - 2017 - SMART-on-FHIR implemented over i2b2..pdf:application/pdf},
}

@article{ayaz_correction_2021,
	title = {Correction: {The} {Fast} {Health} {Interoperability} {Resources} ({FHIR}) {Standard}: {Systematic} {Literature} {Review} of {Implementations}, {Applications}, {Challenges} and {Opportunities}.},
	volume = {9},
	doi = {10.2196/32869},
	abstract = {Background  Information technology has shifted paper-based documentation in the health care sector into a digital form, in which patient information is transferred electronically from one place to another. However, there remain challenges and issues to resolve in this domain owing to the lack of proper standards, the growth of new technologies (mobile devices, tablets, ubiquitous computing), and health care providers who are reluctant to share patient information. Therefore, a solid systematic literature review was performed to understand the use of this new technology in the health care sector. To the best of our knowledge, there is a lack of comprehensive systematic literature reviews that focus on Fast Health Interoperability Resources (FHIR)-based electronic health records (EHRs). In addition, FHIR is the latest standard, which is in an infancy stage of development. Therefore, this is a hot research topic with great potential for further research in this domain.  Objective  The main aim of this study was to explore and perform a systematic review of the literature related to FHIR, including the challenges, implementation, opportunities, and future FHIR applications.  Methods  In January 2020, we searched articles published from January 2012 to December 2019 via all major digital databases in the field of computer science and health care, including ACM, IEEE Explorer, Springer, Google Scholar, PubMed, and ScienceDirect. We identified 8181 scientific articles published in this field, 80 of which met our inclusion criteria for further consideration.  Results  The selected 80 scientific articles were reviewed systematically, and we identified open questions, challenges, implementation models, used resources, beneficiary applications, data migration approaches, and goals of FHIR.  Conclusions  The literature analysis performed in this systematic review highlights the important role of FHIR in the health care domain in the near future.},
	number = {8},
	journal = {JMIR medical informatics},
	author = {Ayaz, Muhammad and Pasha, Muhammad Fermi and Alzahrani, Mohammed and {Mohammed Y. Alzahrani} and Budiarto, Rahmat and {Deris Stiawan} and Stiawan, Deris},
	month = aug,
	year = {2021},
	doi = {10.2196/32869},
	pmcid = {8367140},
	note = {MAG ID: 3195573207},
	file = {Full Text:/Users/damar.pramuditya/Zotero/storage/8IAUNPC2/Ayaz et al. - 2021 - Correction The Fast Health Interoperability Resou.pdf:application/pdf},
}
